{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from langdetect import detect\n",
    "import chardet\n",
    "import warnings\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraping:\n",
    "    \"\"\"\n",
    "    this class will allow us to retrieve the content of our web pages\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def web_name(self, url):\n",
    "        \"\"\"\n",
    "        this function allows to obtain the name which is in url, for example for this url https://www.specshop.pl, the name will be specshop\n",
    "\n",
    "        Args:\n",
    "            url (url): url for the web page\n",
    "\n",
    "        Returns:\n",
    "            str: the name that located of the url\n",
    "        \"\"\"\n",
    "        \n",
    "        return \"\".join(urlparse(url).netloc.split(\".\")[-2])\n",
    "    \n",
    "    def web_title(self, soup):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): get the whole html parse document of the web page \n",
    "\n",
    "        Returns:\n",
    "            str: title of the page\n",
    "        \"\"\"\n",
    "        title = soup.title\n",
    "        return \" \".join(title.contents) if soup.html is not None and \"title\" in soup.html and  title is not None and title.contents is not None else \"\"\n",
    "\n",
    "    \n",
    "    def web_language(self, soup):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): get the whole html parse document of the web page \n",
    "\n",
    "        Returns:\n",
    "            str: language of the page\n",
    "        \"\"\"\n",
    "        try:\n",
    "            language = detect(soup.get_text())\n",
    "        except Exception:\n",
    "            language = \"en\"\n",
    "\n",
    "        return language\n",
    "\n",
    " \n",
    " \n",
    "    def web_meta(self, soup):\n",
    "        \"\"\"\n",
    "        gets some meta data from the web page header\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): get the whole html parse document of the web page\n",
    "\n",
    "        Returns:\n",
    "            str: the description of our page in the header\n",
    "        \"\"\"\n",
    "        \n",
    "        tags = soup.find_all(lambda tag: (tag.name=='meta') & (tag.has_attr('name') & tag.has_attr('content')))\n",
    "        \n",
    "        content = [str(tag['content']) for tag in tags if tag['name'] in ['keywords', 'description']]\n",
    "        return \" \".join(content)\n",
    "    \n",
    "    \n",
    "    def web_header(self, soup):\n",
    "        \"\"\"\n",
    "    \n",
    "        Args:\n",
    "            soup (BeautifulSoup): get the whole html parse document of the web page\n",
    "\n",
    "        Returns:\n",
    "            str: all titles from h1 to h6 of the web page\n",
    "        \"\"\"\n",
    "        \n",
    "        tags = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])\n",
    "        if not tags:\n",
    "            return \"\"\n",
    "        content = [\" \".join(tag.stripped_strings) for tag in tags]\n",
    "        \n",
    "        return \" \".join(content)\n",
    "    \n",
    "    def web_contents(self, soup):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): get the whole html parse document of the web page\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            str: any other element of our html that is not a title, css style, etc...\n",
    "        \"\"\"\n",
    "        \n",
    "        tags_to_ignore = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\",\"h6\", \"noscript\", \"style\", \"script\", \"head\", \"title\", \"meta\", \"[document]\"]\n",
    "        contends = soup.find_all(text=True)\n",
    "        result = []\n",
    "        for word in contends[:50]:\n",
    "            stripped_word = word.strip()\n",
    "        \n",
    "            if (\n",
    "                word.parent.name not in tags_to_ignore\n",
    "                and not isinstance(word, bs4.element.Comment)\n",
    "                and not stripped_word.isnumeric()\n",
    "                and  len(stripped_word) > 0 \n",
    "            ): \n",
    "               \n",
    "                result.append(stripped_word) \n",
    "        return \" \".join(result)\n",
    "        \n",
    "        \n",
    "    def url_contents(self, url):\n",
    "        \"\"\"\n",
    "        return de content of web page\n",
    "        \n",
    "        Args:\n",
    "            url (str): url for the web page\n",
    "\n",
    "        Returns:\n",
    "            Series: content of the web page\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            headers = { \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "                        \n",
    "                       }\n",
    "\n",
    "            response = requests.get(url, timeout=60, headers=headers)\n",
    "            \n",
    "\n",
    "            if response.status_code != 200:\n",
    "                result = {\n",
    "                    \"lang\": \"None\",\n",
    "                    \"url\": \"None\",\n",
    "                    \"website_name\": \"None\",\n",
    "                    \"content_text\": \"None\"\n",
    "                }\n",
    "            else:\n",
    "                \n",
    "                warnings.filterwarnings(\"error\", category=MarkupResemblesLocatorWarning)\n",
    "                warnings.filterwarnings(\"error\", category=UnicodeWarning)\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\", from_encoding=response.encoding) if response.encoding else BeautifulSoup(response.content,    \"html.parser\", from_encoding='utf-8')\n",
    "\n",
    "                ## Detect encoding\n",
    "                #encoding = chardet.detect(response.content)['encoding']\n",
    "        \n",
    "                ## Set encoding to response object\n",
    "                #response.encoding = encoding\n",
    "                #\n",
    "                #soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "                result = {\n",
    "                \"lang\": self.web_language(soup),\n",
    "                \"url\": url,\n",
    "                \"website_name\": self.web_name(url),\n",
    "                \"content_text\": self.web_meta(soup) + self.web_title(soup)+ self.web_header(soup) + self.web_contents(soup)\n",
    "                }\n",
    "                \n",
    "\n",
    "            return pd.Series(result)\n",
    "            \n",
    "                \n",
    "        except (requests.exceptions.RequestException, MarkupResemblesLocatorWarning, UnicodeDecodeError):\n",
    "            result = {\n",
    "                \"lang\": \"None\",\n",
    "                \"url\": url,\n",
    "                \"website_name\": \"None\",\n",
    "                \"content_text\": \"None\"\n",
    "            }\n",
    "            return pd.Series(result) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "class TextCleaner:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nlp_dict = {}\n",
    "        \n",
    "    def clean_text(self, document, lang):\n",
    "        \"\"\"\n",
    "        Cleans and normalizes a text according to the given language\n",
    "\n",
    "        Args:\n",
    "            document (str): a text to clean\n",
    "            lang (str): the language of the document\n",
    "\n",
    "        Returns:\n",
    "            str: the normalized text\n",
    "        \"\"\"\n",
    "        \n",
    "        # load the appropriate template if you have not already done it\n",
    "        if lang not in self.nlp_dict:\n",
    "            lang_dict = {\n",
    "                'en': 'en_core_web_sm',\n",
    "                'fr': 'fr_core_news_sm',\n",
    "                'de': 'de_core_news_sm',\n",
    "                # add other languages if necessary\n",
    "            }\n",
    "\n",
    "            self.nlp_dict[lang] = spacy.load(lang_dict.get(lang, 'en_core_web_sm'))\n",
    "\n",
    "        # normalizes the text with the loaded template\n",
    "        doc = self.nlp_dict[lang](document)\n",
    "        tokens = []\n",
    "        exclusion_list = [\"nan\", \"vml\", \"endif\"]\n",
    "\n",
    "        for token in doc:\n",
    "            if token.is_stop or token.is_punct or token.text.isnumeric() or (token.text.isalnum() == False) or token.text in exclusion_list:\n",
    "                continue\n",
    "\n",
    "            # Normalization of the token to lowercase lemmas\n",
    "            token = str(token.lemma_.lower().strip())\n",
    "            tokens.append(token)\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/119321 [00:57<12:04:28,  2.74it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  1%|          | 1143/119321 [04:43<4:23:40,  7.47it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  2%|▏         | 1981/119321 [07:17<3:04:31, 10.60it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  2%|▏         | 2174/119321 [07:50<4:10:51,  7.78it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  2%|▏         | 2327/119321 [08:21<14:16:48,  2.28it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  2%|▏         | 2659/119321 [09:20<5:12:05,  6.23it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  3%|▎         | 3091/119321 [10:50<4:44:47,  6.80it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  3%|▎         | 3503/119321 [12:25<2:50:41, 11.31it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  3%|▎         | 3711/119321 [12:58<3:40:53,  8.72it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  3%|▎         | 4167/119321 [14:10<4:19:17,  7.40it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  4%|▍         | 4716/119321 [16:00<7:25:51,  4.28it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  4%|▍         | 4958/119321 [16:35<6:25:42,  4.94it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  5%|▌         | 6323/119321 [20:27<2:11:43, 14.30it/s] /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "  6%|▌         | 6767/119321 [21:52<13:13:55,  2.36it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  6%|▌         | 6787/119321 [21:54<3:08:17,  9.96it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  6%|▌         | 6865/119321 [22:14<9:45:20,  3.20it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  6%|▋         | 7705/119321 [24:53<12:20:23,  2.51it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  7%|▋         | 8235/119321 [26:32<4:27:08,  6.93it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  7%|▋         | 8712/119321 [28:05<2:47:27, 11.01it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  8%|▊         | 9076/119321 [29:32<3:39:39,  8.36it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  9%|▉         | 10709/119321 [35:21<5:06:29,  5.91it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "  9%|▉         | 10806/119321 [35:35<3:24:26,  8.85it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 10%|▉         | 11770/119321 [38:00<3:39:01,  8.18it/s] /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 11%|█         | 13185/119321 [41:50<3:57:14,  7.46it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 12%|█▏        | 13746/119321 [43:28<3:46:29,  7.77it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 12%|█▏        | 13814/119321 [43:44<9:00:02,  3.26it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 12%|█▏        | 14829/119321 [47:11<4:52:00,  5.96it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 13%|█▎        | 15595/119321 [49:28<2:51:46, 10.06it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 13%|█▎        | 15729/119321 [49:52<4:07:52,  6.97it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 14%|█▍        | 16565/119321 [52:26<4:35:38,  6.21it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 14%|█▍        | 17162/119321 [54:22<5:43:16,  4.96it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 14%|█▍        | 17274/119321 [54:43<1:58:00, 14.41it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 15%|█▌        | 18148/119321 [57:25<4:38:24,  6.06it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 15%|█▌        | 18299/119321 [57:52<4:37:54,  6.06it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 16%|█▌        | 19011/119321 [1:00:07<3:24:55,  8.16it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 16%|█▋        | 19411/119321 [1:01:29<5:29:21,  5.06it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 17%|█▋        | 19785/119321 [1:02:45<5:34:20,  4.96it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 18%|█▊        | 21214/119321 [1:08:20<5:40:40,  4.80it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 20%|█▉        | 23490/119321 [1:15:27<4:10:18,  6.38it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 23%|██▎       | 27480/119321 [1:26:58<8:47:46,  2.90it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 23%|██▎       | 27677/119321 [1:27:36<6:12:35,  4.10it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 24%|██▎       | 28192/119321 [1:29:05<7:30:40,  3.37it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 25%|██▍       | 29440/119321 [1:34:11<5:33:03,  4.50it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 25%|██▌       | 30146/119321 [1:37:18<5:46:15,  4.29it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 26%|██▌       | 30753/119321 [1:39:07<4:15:58,  5.77it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 26%|██▌       | 30821/119321 [1:39:17<3:24:58,  7.20it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 26%|██▌       | 31187/119321 [1:40:24<7:52:34,  3.11it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 26%|██▋       | 31469/119321 [1:41:06<6:48:53,  3.58it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 31820/119321 [1:42:09<5:15:56,  4.62it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 31838/119321 [1:42:13<5:06:02,  4.76it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 31927/119321 [1:42:24<2:01:57, 11.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 32067/119321 [1:43:03<6:24:49,  3.78it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 32074/119321 [1:43:06<9:14:13,  2.62it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 32118/119321 [1:43:12<2:46:54,  8.71it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 27%|██▋       | 32364/119321 [1:43:50<3:50:49,  6.28it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 28%|██▊       | 33308/119321 [1:46:41<5:06:57,  4.67it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 28%|██▊       | 33744/119321 [1:47:52<9:49:00,  2.42it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 29%|██▊       | 34171/119321 [1:48:58<3:49:59,  6.17it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 30%|██▉       | 35444/119321 [1:52:08<4:01:22,  5.79it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 30%|███       | 35963/119321 [1:53:31<1:56:42, 11.90it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 30%|███       | 36346/119321 [1:54:32<3:04:04,  7.51it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 31%|███       | 36729/119321 [1:55:35<3:28:41,  6.60it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 31%|███       | 36899/119321 [1:56:01<16:10:05,  1.42it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 31%|███▏      | 37476/119321 [1:57:26<5:43:31,  3.97it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 31%|███▏      | 37524/119321 [1:57:36<3:09:19,  7.20it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 32%|███▏      | 37724/119321 [1:58:08<4:16:27,  5.30it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 39184/119321 [2:02:00<3:24:02,  6.55it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▎      | 40060/119321 [2:04:20<4:03:33,  5.42it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▎      | 40215/119321 [2:04:56<7:31:42,  2.92it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▍      | 40441/119321 [2:05:34<4:32:24,  4.83it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▍      | 40513/119321 [2:05:49<5:13:42,  4.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▍      | 40937/119321 [2:07:10<4:56:00,  4.41it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 34%|███▍      | 41032/119321 [2:07:25<6:51:44,  3.17it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 35%|███▍      | 41355/119321 [2:08:29<3:22:41,  6.41it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 35%|███▍      | 41456/119321 [2:08:49<6:31:02,  3.32it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 35%|███▌      | 41787/119321 [2:09:41<6:12:38,  3.47it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 35%|███▌      | 41926/119321 [2:10:01<4:49:45,  4.45it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 35%|███▌      | 42011/119321 [2:10:16<3:16:52,  6.54it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 36%|███▌      | 42435/119321 [2:11:34<7:19:32,  2.92it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 36%|███▌      | 42650/119321 [2:12:09<4:58:53,  4.28it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 36%|███▌      | 42754/119321 [2:12:34<7:58:41,  2.67it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 36%|███▋      | 43297/119321 [2:14:17<11:04:48,  1.91it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 37%|███▋      | 43712/119321 [2:15:33<6:11:59,  3.39it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 37%|███▋      | 44508/119321 [2:17:59<2:22:21,  8.76it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 38%|███▊      | 44782/119321 [2:18:45<7:03:41,  2.93it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 38%|███▊      | 44829/119321 [2:18:54<4:16:46,  4.84it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 38%|███▊      | 44851/119321 [2:19:03<7:59:20,  2.59it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 38%|███▊      | 44938/119321 [2:19:21<5:07:31,  4.03it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 38%|███▊      | 45587/119321 [2:21:00<4:02:08,  5.08it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 39%|███▉      | 46528/119321 [2:23:31<2:20:23,  8.64it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 39%|███▉      | 46786/119321 [2:24:16<4:55:01,  4.10it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 39%|███▉      | 47017/119321 [2:24:56<4:48:00,  4.18it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 39%|███▉      | 47105/119321 [2:25:10<5:44:57,  3.49it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 40%|███▉      | 47137/119321 [2:25:14<4:31:28,  4.43it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 40%|███▉      | 47453/119321 [2:26:03<4:02:17,  4.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 40%|███▉      | 47662/119321 [2:26:49<8:33:14,  2.33it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 40%|███▉      | 47682/119321 [2:26:51<1:09:48, 17.11it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 40%|████      | 48083/119321 [2:27:54<1:18:09, 15.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 41%|████      | 48329/119321 [2:28:32<5:17:26,  3.73it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 41%|████      | 48973/119321 [2:30:25<6:47:01,  2.88it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 41%|████▏     | 49337/119321 [2:31:27<8:43:47,  2.23it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 41%|████▏     | 49369/119321 [2:31:40<2:57:19,  6.57it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 41%|████▏     | 49411/119321 [2:31:47<6:22:39,  3.04it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 42%|████▏     | 49584/119321 [2:32:13<3:01:24,  6.41it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 42%|████▏     | 49623/119321 [2:32:23<4:37:12,  4.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 42%|████▏     | 49771/119321 [2:32:55<7:38:29,  2.53it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 42%|████▏     | 49854/119321 [2:33:12<4:17:55,  4.49it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 42%|████▏     | 50422/119321 [2:34:47<5:07:11,  3.74it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 43%|████▎     | 51167/119321 [2:36:48<5:56:47,  3.18it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 43%|████▎     | 51381/119321 [2:37:25<4:16:49,  4.41it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 43%|████▎     | 51494/119321 [2:37:45<4:16:20,  4.41it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 43%|████▎     | 51733/119321 [2:38:35<3:49:48,  4.90it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 44%|████▍     | 52215/119321 [2:40:09<2:50:05,  6.58it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 44%|████▍     | 52352/119321 [2:40:30<4:24:28,  4.22it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 44%|████▍     | 52607/119321 [2:41:09<7:56:28,  2.33it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 44%|████▍     | 53068/119321 [2:42:28<6:48:40,  2.70it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▍     | 53267/119321 [2:43:04<2:38:34,  6.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▍     | 53682/119321 [2:44:26<8:09:33,  2.23it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▌     | 53823/119321 [2:44:49<2:08:17,  8.51it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▌     | 53870/119321 [2:45:00<6:34:21,  2.77it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▌     | 53945/119321 [2:45:10<2:39:32,  6.83it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 45%|████▌     | 54182/119321 [2:45:49<5:42:44,  3.17it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▌     | 54501/119321 [2:46:36<6:34:29,  2.74it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▌     | 54805/119321 [2:47:24<4:07:01,  4.35it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▌     | 54809/119321 [2:47:26<7:21:12,  2.44it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▌     | 55002/119321 [2:47:56<1:12:09, 14.86it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▌     | 55163/119321 [2:48:19<1:30:31, 11.81it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▋     | 55355/119321 [2:48:56<1:23:20, 12.79it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▋     | 55370/119321 [2:49:00<3:11:20,  5.57it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 46%|████▋     | 55393/119321 [2:49:05<3:05:03,  5.76it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 47%|████▋     | 56060/119321 [2:50:53<3:13:09,  5.46it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 56726/119321 [2:52:36<1:35:30, 10.92it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 56823/119321 [2:52:52<1:32:45, 11.23it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 56966/119321 [2:53:16<3:13:01,  5.38it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 57260/119321 [2:54:02<3:39:53,  4.70it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 57370/119321 [2:54:21<1:47:47,  9.58it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 57439/119321 [2:54:35<2:03:22,  8.36it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 48%|████▊     | 57602/119321 [2:55:07<5:51:07,  2.93it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 49%|████▉     | 58726/119321 [2:58:14<3:31:28,  4.78it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 49%|████▉     | 59003/119321 [2:58:54<1:07:54, 14.81it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|████▉     | 59156/119321 [2:59:25<5:58:18,  2.80it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|████▉     | 59179/119321 [2:59:30<3:45:30,  4.44it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|████▉     | 59278/119321 [2:59:53<4:22:30,  3.81it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|████▉     | 59340/119321 [3:00:05<3:57:47,  4.20it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|████▉     | 59362/119321 [3:00:10<3:33:05,  4.69it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|█████     | 59865/119321 [3:01:30<1:34:50, 10.45it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|█████     | 59894/119321 [3:01:37<3:31:12,  4.69it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|█████     | 59916/119321 [3:01:41<4:05:05,  4.04it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 50%|█████     | 59919/119321 [3:01:45<7:27:04,  2.21it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████     | 60536/119321 [3:03:31<4:49:32,  3.38it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████     | 60654/119321 [3:03:55<8:31:24,  1.91it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████     | 60789/119321 [3:04:19<2:43:24,  5.97it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████     | 60819/119321 [3:04:25<1:24:38, 11.52it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████     | 61085/119321 [3:05:20<6:08:02,  2.64it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████▏    | 61213/119321 [3:05:40<3:51:21,  4.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████▏    | 61215/119321 [3:05:43<8:31:18,  1.89it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 51%|█████▏    | 61236/119321 [3:05:47<4:13:50,  3.81it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 52%|█████▏    | 61525/119321 [3:06:33<4:19:35,  3.71it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 52%|█████▏    | 61601/119321 [3:06:48<1:35:36, 10.06it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 52%|█████▏    | 62414/119321 [3:09:17<2:24:39,  6.56it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 52%|█████▏    | 62442/119321 [3:09:25<5:20:55,  2.95it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 52%|█████▏    | 62566/119321 [3:09:46<4:04:42,  3.87it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 53%|█████▎    | 63087/119321 [3:11:30<2:33:35,  6.10it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 53%|█████▎    | 63601/119321 [3:13:18<2:56:40,  5.26it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 53%|█████▎    | 63621/119321 [3:13:22<2:52:00,  5.40it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 63988/119321 [3:14:25<2:21:46,  6.50it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 63998/119321 [3:14:31<5:11:38,  2.96it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 64002/119321 [3:14:32<5:12:06,  2.95it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 64027/119321 [3:14:40<7:29:25,  2.05it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 64049/119321 [3:14:45<5:11:23,  2.96it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▎    | 64105/119321 [3:14:56<5:11:19,  2.96it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64152/119321 [3:15:04<2:18:20,  6.65it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64173/119321 [3:15:10<3:49:37,  4.00it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64198/119321 [3:15:16<2:58:29,  5.15it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64240/119321 [3:15:28<2:06:54,  7.23it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64244/119321 [3:15:33<5:30:41,  2.78it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64268/119321 [3:15:36<3:01:32,  5.05it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64293/119321 [3:15:42<4:14:18,  3.61it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64384/119321 [3:16:05<3:55:34,  3.89it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64494/119321 [3:16:24<1:37:47,  9.34it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64538/119321 [3:16:35<2:51:17,  5.33it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64557/119321 [3:16:37<1:32:24,  9.88it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64685/119321 [3:17:06<1:27:24, 10.42it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64688/119321 [3:17:10<6:54:17,  2.20it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64731/119321 [3:17:20<4:32:06,  3.34it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64816/119321 [3:17:34<2:55:15,  5.18it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64850/119321 [3:17:42<3:51:29,  3.92it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64875/119321 [3:17:50<4:01:47,  3.75it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64900/119321 [3:17:57<6:28:10,  2.34it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64929/119321 [3:18:03<3:19:52,  4.54it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 64932/119321 [3:18:09<9:22:36,  1.61it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 54%|█████▍    | 65028/119321 [3:18:26<4:07:27,  3.66it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 55%|█████▍    | 65289/119321 [3:19:16<5:01:27,  2.99it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▌    | 66242/119321 [3:21:51<2:32:38,  5.80it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▌    | 66331/119321 [3:22:06<2:57:16,  4.98it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▌    | 66949/119321 [3:23:49<2:59:42,  4.86it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▌    | 67069/119321 [3:24:10<2:50:50,  5.10it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▋    | 67387/119321 [3:25:06<1:35:15,  9.09it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 56%|█████▋    | 67416/119321 [3:25:15<2:32:13,  5.68it/s] /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 57%|█████▋    | 67501/119321 [3:25:30<3:18:05,  4.36it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 57%|█████▋    | 67543/119321 [3:25:40<2:32:46,  5.65it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 57%|█████▋    | 67753/119321 [3:26:23<8:27:45,  1.69it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 58%|█████▊    | 69030/119321 [3:29:57<1:17:28, 10.82it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 58%|█████▊    | 69625/119321 [3:31:52<5:11:48,  2.66it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 59%|█████▊    | 70051/119321 [3:33:13<1:25:08,  9.65it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|█████▉    | 71113/119321 [3:36:59<2:08:44,  6.24it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71645/119321 [3:38:29<6:57:36,  1.90it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71680/119321 [3:38:34<1:29:33,  8.87it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71690/119321 [3:38:40<4:48:10,  2.75it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 60%|██████    | 71709/119321 [3:38:43<2:12:41,  5.98it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71887/119321 [3:39:13<2:46:28,  4.75it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71943/119321 [3:39:23<2:37:37,  5.01it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 60%|██████    | 71999/119321 [3:39:33<2:06:52,  6.22it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 61%|██████    | 72338/119321 [3:40:30<2:05:58,  6.22it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 61%|██████    | 72424/119321 [3:40:42<1:46:54,  7.31it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 61%|██████    | 72564/119321 [3:41:01<2:16:55,  5.69it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 61%|██████    | 72581/119321 [3:41:03<47:53, 16.27it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 62%|██████▏   | 73408/119321 [3:43:30<4:52:33,  2.62it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 62%|██████▏   | 73782/119321 [3:44:38<5:29:34,  2.30it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 62%|██████▏   | 74269/119321 [3:46:03<1:44:37,  7.18it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 62%|██████▏   | 74327/119321 [3:46:15<1:46:51,  7.02it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 62%|██████▏   | 74357/119321 [3:46:22<1:41:17,  7.40it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 62%|██████▏   | 74506/119321 [3:46:57<5:49:12,  2.14it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 63%|██████▎   | 74894/119321 [3:48:08<2:11:48,  5.62it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 63%|██████▎   | 75590/119321 [3:50:18<1:53:19,  6.43it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 63%|██████▎   | 75742/119321 [3:50:42<1:06:15, 10.96it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 65%|██████▍   | 77016/119321 [3:54:26<3:18:34,  3.55it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 65%|██████▍   | 77061/119321 [3:54:33<54:06, 13.02it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 65%|██████▍   | 77443/119321 [3:55:50<6:33:18,  1.77it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 65%|██████▌   | 77656/119321 [3:56:26<1:56:18,  5.97it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 65%|██████▌   | 77853/119321 [3:56:59<1:18:17,  8.83it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 65%|██████▌   | 77971/119321 [3:57:29<12:09:17,  1.06s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 66%|██████▌   | 78199/119321 [3:58:22<2:55:04,  3.91it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 66%|██████▌   | 78342/119321 [3:58:50<1:02:39, 10.90it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 66%|██████▌   | 78640/119321 [3:59:46<2:35:13,  4.37it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 66%|██████▌   | 79050/119321 [4:00:59<1:01:20, 10.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 66%|██████▋   | 79173/119321 [4:01:20<2:49:37,  3.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 67%|██████▋   | 79609/119321 [4:02:40<59:35, 11.11it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 67%|██████▋   | 80012/119321 [4:03:48<1:34:41,  6.92it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 67%|██████▋   | 80088/119321 [4:04:04<1:38:20,  6.65it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 68%|██████▊   | 80574/119321 [4:05:29<1:06:26,  9.72it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 68%|██████▊   | 81116/119321 [4:07:19<1:45:56,  6.01it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 68%|██████▊   | 81409/119321 [4:08:09<1:22:45,  7.64it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 68%|██████▊   | 81518/119321 [4:08:33<1:44:25,  6.03it/s] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 69%|██████▉   | 82415/119321 [4:11:17<1:51:43,  5.51it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 70%|██████▉   | 83017/119321 [4:12:59<1:38:18,  6.16it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 70%|███████   | 83653/119321 [4:14:53<1:51:02,  5.35it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 71%|███████   | 84273/119321 [4:16:42<2:23:26,  4.07it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 71%|███████   | 84666/119321 [4:17:52<1:58:45,  4.86it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 71%|███████▏  | 85130/119321 [4:19:19<2:44:50,  3.46it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 71%|███████▏  | 85132/119321 [4:19:20<2:22:31,  4.00it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 72%|███████▏  | 85438/119321 [4:20:14<3:19:38,  2.83it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 72%|███████▏  | 85792/119321 [4:21:08<1:19:53,  6.99it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 72%|███████▏  | 86269/119321 [4:22:32<59:19,  9.28it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 72%|███████▏  | 86399/119321 [4:22:56<3:10:31,  2.88it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 86513/119321 [4:23:17<1:24:01,  6.51it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 86668/119321 [4:23:44<1:04:26,  8.44it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 87007/119321 [4:24:50<3:53:49,  2.30it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 87399/119321 [4:26:03<1:12:44,  7.31it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 87464/119321 [4:26:13<1:00:12,  8.82it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 73%|███████▎  | 87472/119321 [4:26:14<52:36, 10.09it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 74%|███████▎  | 87923/119321 [4:27:37<1:28:30,  5.91it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 74%|███████▍  | 88026/119321 [4:27:54<32:48, 15.90it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 74%|███████▍  | 88192/119321 [4:28:20<1:08:56,  7.52it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 75%|███████▍  | 89168/119321 [4:31:03<59:17,  8.47it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 75%|███████▍  | 89298/119321 [4:31:24<1:17:03,  6.49it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 75%|███████▍  | 89387/119321 [4:31:43<1:16:43,  6.50it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 75%|███████▌  | 89831/119321 [4:33:07<1:55:00,  4.27it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 75%|███████▌  | 90058/119321 [4:33:47<1:24:16,  5.79it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 76%|███████▌  | 90420/119321 [4:34:51<53:27,  9.01it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 76%|███████▌  | 90544/119321 [4:35:14<1:22:07,  5.84it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 76%|███████▌  | 90906/119321 [4:36:31<51:29,  9.20it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 76%|███████▋  | 91217/119321 [4:37:32<50:29,  9.28it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 77%|███████▋  | 91365/119321 [4:37:59<1:09:37,  6.69it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 91393/119321 [4:38:06<1:18:24,  5.94it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 91395/119321 [4:38:08<2:34:10,  3.02it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 92007/119321 [4:40:00<1:23:30,  5.45it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 77%|███████▋  | 92236/119321 [4:40:40<3:12:49,  2.34it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 78%|███████▊  | 92624/119321 [4:41:44<25:58, 17.14it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 78%|███████▊  | 93372/119321 [4:44:14<1:39:08,  4.36it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 78%|███████▊  | 93420/119321 [4:44:26<1:39:11,  4.35it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 78%|███████▊  | 93535/119321 [4:44:47<1:37:41,  4.40it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▊  | 93760/119321 [4:45:30<53:59,  7.89it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▊  | 93892/119321 [4:45:54<1:12:10,  5.87it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94046/119321 [4:46:21<1:32:39,  4.55it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94104/119321 [4:46:35<3:55:39,  1.78it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94236/119321 [4:46:55<43:31,  9.60it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94354/119321 [4:47:23<1:14:28,  5.59it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94517/119321 [4:48:02<1:49:31,  3.77it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94589/119321 [4:48:16<1:40:09,  4.12it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94620/119321 [4:49:16<12:49:03,  1.87s/it]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94625/119321 [4:49:20<9:22:17,  1.37s/it] Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 79%|███████▉  | 94626/119321 [4:49:20<6:50:12,  1.00it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 80%|███████▉  | 94954/119321 [4:50:25<55:55,  7.26it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 80%|███████▉  | 95309/119321 [4:51:38<4:39:05,  1.43it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 80%|████████  | 95731/119321 [4:52:45<39:54,  9.85it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 80%|████████  | 96034/119321 [4:53:40<1:55:45,  3.35it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 81%|████████  | 96397/119321 [4:54:48<1:03:27,  6.02it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 81%|████████  | 96534/119321 [4:55:17<1:19:19,  4.79it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 81%|████████▏ | 97239/119321 [4:57:21<2:39:08,  2.31it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 82%|████████▏ | 97452/119321 [4:57:59<1:50:17,  3.30it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 82%|████████▏ | 97687/119321 [4:58:37<1:29:35,  4.02it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 82%|████████▏ | 97889/119321 [4:59:13<1:13:13,  4.88it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 82%|████████▏ | 98348/119321 [5:00:37<45:01,  7.76it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 83%|████████▎ | 98720/119321 [5:01:43<1:18:35,  4.37it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 98825/119321 [5:02:02<50:08,  6.81it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 83%|████████▎ | 99336/119321 [5:03:30<51:59,  6.41it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 83%|████████▎ | 99391/119321 [5:03:43<1:14:00,  4.49it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 83%|████████▎ | 99455/119321 [5:03:57<2:01:09,  2.73it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 84%|████████▎ | 99672/119321 [5:04:39<34:41,  9.44it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 84%|████████▍ | 99944/119321 [5:05:29<1:21:59,  3.94it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 84%|████████▍ | 100248/119321 [5:06:25<49:05,  6.48it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 100350/119321 [5:06:40<40:27,  7.82it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 84%|████████▍ | 100462/119321 [5:06:58<46:20,  6.78it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 84%|████████▍ | 100533/119321 [5:07:09<38:34,  8.12it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 85%|████████▌ | 101920/119321 [5:11:18<1:31:12,  3.18it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 86%|████████▌ | 102367/119321 [5:12:33<47:33,  5.94it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 103221/119321 [5:14:54<25:33, 10.50it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 103383/119321 [5:15:25<2:01:24,  2.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 103384/119321 [5:15:25<1:55:09,  2.31it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 103420/119321 [5:15:33<1:47:44,  2.46it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 103793/119321 [5:16:43<42:48,  6.04it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 87%|████████▋ | 104017/119321 [5:17:22<37:02,  6.89it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 88%|████████▊ | 104548/119321 [5:18:56<1:00:16,  4.08it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 88%|████████▊ | 105042/119321 [5:20:20<52:08,  4.56it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 89%|████████▊ | 105635/119321 [5:22:01<26:57,  8.46it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 89%|████████▊ | 105858/119321 [5:22:41<33:22,  6.72it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 89%|████████▉ | 105930/119321 [5:22:51<20:16, 11.01it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 89%|████████▉ | 105956/119321 [5:22:56<40:12,  5.54it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 89%|████████▉ | 106328/119321 [5:24:07<52:40,  4.11it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 90%|████████▉ | 107269/119321 [5:27:08<1:05:26,  3.07it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 90%|████████▉ | 107343/119321 [5:27:23<42:59,  4.64it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 90%|█████████ | 107447/119321 [5:27:42<42:39,  4.64it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 90%|█████████ | 107459/119321 [5:27:44<23:20,  8.47it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 90%|█████████ | 107626/119321 [5:28:17<28:30,  6.84it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 90%|█████████ | 107961/119321 [5:29:17<52:47,  3.59it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 91%|█████████ | 108349/119321 [5:30:27<40:21,  4.53it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 91%|█████████ | 108633/119321 [5:31:18<25:21,  7.03it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 92%|█████████▏| 109182/119321 [5:32:46<13:21, 12.64it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 92%|█████████▏| 109677/119321 [5:34:15<28:34,  5.62it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 93%|█████████▎| 111153/119321 [5:38:32<24:00,  5.67it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 93%|█████████▎| 111421/119321 [5:39:19<27:45,  4.74it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 94%|█████████▍| 111866/119321 [5:40:49<20:48,  5.97it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 94%|█████████▍| 112379/119321 [5:42:38<19:38,  5.89it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 94%|█████████▍| 112382/119321 [5:42:42<53:01,  2.18it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 95%|█████████▍| 112784/119321 [5:44:04<17:05,  6.38it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 95%|█████████▍| 113002/119321 [5:44:54<18:59,  5.54it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 95%|█████████▍| 113137/119321 [5:45:27<14:11,  7.26it/s]  /home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 95%|█████████▌| 113610/119321 [5:47:07<09:58,  9.55it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 95%|█████████▌| 113884/119321 [5:48:04<08:11, 11.06it/s]  Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 96%|█████████▌| 114288/119321 [5:49:34<11:47,  7.12it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 96%|█████████▋| 115069/119321 [5:52:24<09:27,  7.49it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 97%|█████████▋| 115489/119321 [5:53:49<13:35,  4.70it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 97%|█████████▋| 116110/119321 [5:55:54<12:56,  4.13it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 97%|█████████▋| 116231/119321 [5:56:18<04:10, 12.34it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 98%|█████████▊| 116634/119321 [5:57:46<07:36,  5.89it/s]/home/ljatsa/.local/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 98%|█████████▊| 117294/119321 [5:59:52<05:39,  5.97it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 98%|█████████▊| 117367/119321 [6:00:06<08:39,  3.76it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 98%|█████████▊| 117513/119321 [6:00:33<04:01,  7.49it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 99%|█████████▉| 117913/119321 [6:01:41<01:39, 14.19it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      " 99%|█████████▉| 118344/119321 [6:03:03<01:29, 10.97it/s]Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "100%|██████████| 119321/119321 [6:07:00<00:00,  5.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures # module for running functions in parallel\n",
    "import json\n",
    "import pandas as pd \n",
    "from tqdm import tqdm  # module to create a progress bar\n",
    "\n",
    "\n",
    "\n",
    "def extract_data(domaine, scrap, cleaner):\n",
    "    \"\"\"\n",
    "    (upgrade)Function to extract data from a line in our json file\n",
    "\n",
    "    Args:\n",
    "        domaine (dict): Line of the json file\n",
    "        scrap (Scraping): instance of the Scraping class\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary containing the extracted information\n",
    "    \"\"\"\n",
    "    list_lang = []\n",
    "    try:\n",
    "        dict_domaine = json.loads(domaine)\n",
    "        name = dict_domaine['name']\n",
    "        category = dict_domaine['category']\n",
    "        address = dict_domaine['address']\n",
    "        \n",
    "        content = dict(scrap.url_contents(address))\n",
    "        if content[\"lang\"] != \"None\":\n",
    "            list_lang.append(content['lang'])\n",
    "            content['content_text'] = content['content_text'].strip()\n",
    "            if len(content['content_text'])>=20:\n",
    "                text = cleaner.clean_text(content['content_text'], content['lang'])  # clean up the extracted text\n",
    "                # return a dictionary containing the extracted information\n",
    "                return {'name': name, 'category': category, 'address': address, 'language':content['lang'], 'words': text}\n",
    "    except Exception as e:\n",
    "        print(f\"Error when extracting data for the domain {address}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def get_dataSet(file_name: str):\n",
    "    \"\"\"\n",
    "    (upgrade)Read a JSON file containing domain names, extract the keywords associated with each address and return a pandas Dataframe containing the extracted information\n",
    "\n",
    "    Args:\n",
    "        file_name (str): json file \n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Panda Dataframe with extracted data\n",
    "    \"\"\"\n",
    "    \n",
    "    # create an instance of the Scraping class and TextCleaner to extract data from each domain\n",
    "    scrap = Scraping()\n",
    "    cleaner = TextCleaner()\n",
    "    \n",
    "    # open the JSON file and extract the information\n",
    "    with open(file_name, \"r\") as f:\n",
    "        domaines = f.readlines()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:  # execute functions in parallel with 60 threads\n",
    "        futures = [executor.submit(extract_data, domaine, scrap, cleaner) for domaine in domaines]  # submit tasks\n",
    "        results = []  # initialise the list to store the results\n",
    "        \n",
    "        with tqdm(total=len(domaines)) as pbar:  # create a progress bar to display progress\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result is not None:  # if the task has been executed successfully, add the result to the list\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error when extracting data: {e}\")\n",
    "                pbar.update(1)  # update of the progress bar\n",
    "                \n",
    "    # Create a pandas Dataframe containing the extracted data\n",
    "    data = pd.DataFrame(results)\n",
    "    data['indice'] = range(len(data))\n",
    "    data = data.set_index('indice')\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = get_dataSet('urls.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "lang = data.language\n",
    "lang_u = lang.unique()\n",
    "len(lang_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108258 entries, 0 to 108257\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   name      108258 non-null  object\n",
      " 1   category  108258 non-null  object\n",
      " 2   address   108258 non-null  object\n",
      " 3   language  108258 non-null  object\n",
      " 4   words     107942 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108258</td>\n",
       "      <td>108258</td>\n",
       "      <td>108258</td>\n",
       "      <td>108258</td>\n",
       "      <td>107942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>100791</td>\n",
       "      <td>55</td>\n",
       "      <td>95497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>General Business</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>en</td>\n",
       "      <td>enable javascript browser order use site click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>40182</td>\n",
       "      <td>38665</td>\n",
       "      <td>5</td>\n",
       "      <td>68443</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name          category                     address language  \\\n",
       "count    108258            108258                      108258   108258   \n",
       "unique       20               250                      100791       55   \n",
       "top     Unknown  General Business  https://www.homeless.co.il       en   \n",
       "freq      40182             38665                           5    68443   \n",
       "\n",
       "                                                    words  \n",
       "count                                              107942  \n",
       "unique                                              95497  \n",
       "top     enable javascript browser order use site click...  \n",
       "freq                                                  837  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[\"words\"].value_counts()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>Finance / Investment</td>\n",
       "      <td>Financial Services / Insurance / Real Estate</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>he</td>\n",
       "      <td>דירות להשכרה דירות למכירה דירות שותפים נדלן מס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>Finance / Investment</td>\n",
       "      <td>Financial Services / Insurance / Real Estate</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>he</td>\n",
       "      <td>דירות להשכרה דירות למכירה דירות שותפים נדלן מס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12977</th>\n",
       "      <td>Finance / Investment</td>\n",
       "      <td>Financial Services / Insurance / Real Estate</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>he</td>\n",
       "      <td>דירות להשכרה דירות למכירה דירות שותפים נדלן מס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>Finance / Investment</td>\n",
       "      <td>Financial Services / Insurance / Real Estate</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>he</td>\n",
       "      <td>דירות להשכרה דירות למכירה דירות שותפים נדלן מס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27115</th>\n",
       "      <td>Finance / Investment</td>\n",
       "      <td>Financial Services / Insurance / Real Estate</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>he</td>\n",
       "      <td>דירות להשכרה דירות למכירה דירות שותפים נדלן מס...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                                      category  \\\n",
       "3951   Finance / Investment  Financial Services / Insurance / Real Estate   \n",
       "8575   Finance / Investment  Financial Services / Insurance / Real Estate   \n",
       "12977  Finance / Investment  Financial Services / Insurance / Real Estate   \n",
       "18942  Finance / Investment  Financial Services / Insurance / Real Estate   \n",
       "27115  Finance / Investment  Financial Services / Insurance / Real Estate   \n",
       "\n",
       "                          address language  \\\n",
       "3951   https://www.homeless.co.il       he   \n",
       "8575   https://www.homeless.co.il       he   \n",
       "12977  https://www.homeless.co.il       he   \n",
       "18942  https://www.homeless.co.il       he   \n",
       "27115  https://www.homeless.co.il       he   \n",
       "\n",
       "                                                   words  \n",
       "3951   דירות להשכרה דירות למכירה דירות שותפים נדלן מס...  \n",
       "8575   דירות להשכרה דירות למכירה דירות שותפים נדלן מס...  \n",
       "12977  דירות להשכרה דירות למכירה דירות שותפים נדלן מס...  \n",
       "18942  דירות להשכרה דירות למכירה דירות שותפים נדלן מס...  \n",
       "27115  דירות להשכרה דירות למכירה דירות שותפים נדלן מס...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b = data[data.address == \"https://www.homeless.co.il\"]\n",
    "data_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101514</td>\n",
       "      <td>101514</td>\n",
       "      <td>101514</td>\n",
       "      <td>101514</td>\n",
       "      <td>101212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>100791</td>\n",
       "      <td>55</td>\n",
       "      <td>95497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>General Business</td>\n",
       "      <td>https://dandelife.com</td>\n",
       "      <td>en</td>\n",
       "      <td>enable javascript browser order use site click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>40158</td>\n",
       "      <td>38641</td>\n",
       "      <td>4</td>\n",
       "      <td>63997</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name          category                address language  \\\n",
       "count    101514            101514                 101514   101514   \n",
       "unique       20               250                 100791       55   \n",
       "top     Unknown  General Business  https://dandelife.com       en   \n",
       "freq      40158             38641                      4    63997   \n",
       "\n",
       "                                                    words  \n",
       "count                                              101212  \n",
       "unique                                              95497  \n",
       "top     enable javascript browser order use site click...  \n",
       "freq                                                  825  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107942</td>\n",
       "      <td>107942</td>\n",
       "      <td>107942</td>\n",
       "      <td>107942</td>\n",
       "      <td>107942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>100489</td>\n",
       "      <td>55</td>\n",
       "      <td>95497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>General Business</td>\n",
       "      <td>https://www.homeless.co.il</td>\n",
       "      <td>en</td>\n",
       "      <td>enable javascript browser order use site click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>40004</td>\n",
       "      <td>38489</td>\n",
       "      <td>5</td>\n",
       "      <td>68383</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name          category                     address language  \\\n",
       "count    107942            107942                      107942   107942   \n",
       "unique       20               250                      100489       55   \n",
       "top     Unknown  General Business  https://www.homeless.co.il       en   \n",
       "freq      40004             38489                           5    68383   \n",
       "\n",
       "                                                    words  \n",
       "count                                              107942  \n",
       "unique                                              95497  \n",
       "top     enable javascript browser order use site click...  \n",
       "freq                                                  837  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_drop.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique = data_drop.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101212</td>\n",
       "      <td>101212</td>\n",
       "      <td>101212</td>\n",
       "      <td>101212</td>\n",
       "      <td>101212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20</td>\n",
       "      <td>250</td>\n",
       "      <td>100489</td>\n",
       "      <td>55</td>\n",
       "      <td>95497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>General Business</td>\n",
       "      <td>https://gp24.pl</td>\n",
       "      <td>en</td>\n",
       "      <td>enable javascript browser order use site click...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>39980</td>\n",
       "      <td>38465</td>\n",
       "      <td>4</td>\n",
       "      <td>63939</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name          category          address language  \\\n",
       "count    101212            101212           101212   101212   \n",
       "unique       20               250           100489       55   \n",
       "top     Unknown  General Business  https://gp24.pl       en   \n",
       "freq      39980             38465                4    63939   \n",
       "\n",
       "                                                    words  \n",
       "count                                              101212  \n",
       "unique                                              95497  \n",
       "top     enable javascript browser order use site click...  \n",
       "freq                                                  825  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste_supr = ['ko', 'th', 'ru', 'tr', 'bg', 'uk', 'af', 'lv', 'el', 'te', 'fi', 'bn', 'hi', 'lt', 'tl',\n",
    "#        'sw', 'mk', 'sq', 'mr', 'so', 'cy', 'zh-tw', 'ur', 'gu', 'ne',\n",
    "#        'pa', 'kn', 'sv', 'ja', 'ar', 'zh-cn', 'vi', 'cs', 'hu', 'he',\n",
    "#        'id', 'it', 'hr', 'da', 'pt', 'sk', 'no', 'ro', 'ml', 'ta', 'et']\n",
    "\n",
    "# masque = data_unique[\"language\"].isin(liste_supr)\n",
    "# lignes_a_supprimer = data_unique[masque].index\n",
    "# data_unique1 = data_unique.drop(lignes_a_supprimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16917\n",
      "17041\n"
     ]
    }
   ],
   "source": [
    "word1= data_unique[data_unique.address == 'https://gp24.pl'].words.unique()[0] \n",
    "word2= data_unique[data_unique.address == 'https://gp24.pl'].words.unique()[1] \n",
    "print(len(word1))\n",
    "print(len(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enable javascript browser order use site click link instruction'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique.describe().words.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, category, address, language, words]\n",
       "Index: []"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = 'enable javascript browser order use site click link instruction'\n",
    "masque = data_unique['words'] == cut\n",
    "move_line = data_unique.loc[masque].index\n",
    "data_unique1 = data_unique.drop(move_line)\n",
    "data_unique1.describe()\n",
    "data_unique1.loc[masque]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>address</th>\n",
       "      <th>language</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, category, address, language, words]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut2 = \"domain request domain security detailsthis domain digital publisher control access copyright content accordance digital millennium copyright act understand visitor access copyright content domain accept post request industry standard http port tcp tcp udp traffic originate consumer web browser request contain metric help site owner understanding authorize access site copyright content header return prevent cache discourage proxy intermediary cache store content domain utilize alive connection multiplex multiple request single connection order prevent have open multiple connection request domain use tls high possible certificate rotate frequently content serve domain consist javascript html css video image executable file available content routinely scan malware malicious software hostname fen hoothoot europe west1 w5gn datacenter gce europe west1\"\n",
    "\n",
    "masque1 = data_unique1['words'] == cut2\n",
    "move_line = data_unique1.loc[masque1].index\n",
    "data_unique2 = data_unique1.drop(move_line)\n",
    "data_unique2.describe().words.top\n",
    "data_unique2.loc[masque1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index modify size description cgi'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut3 = 'welcome page nginx web server successfully instal work configuration require online documentation support refer commercial support available thank nginx'\n",
    "masque2 = data_unique2['words'] == cut3\n",
    "move_line = data_unique2.loc[masque2].index\n",
    "data_unique3 = data_unique2.drop(move_line)\n",
    "data_unique3.describe().words.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'网站改版中our website construction'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut4 = 'index modify size description cgi'\n",
    "masque3 = data_unique3['words'] == cut4\n",
    "move_line = data_unique3.loc[masque3].index\n",
    "data_unique4 = data_unique3.drop(move_line)\n",
    "data_unique4.describe().words.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut5 = '网站改版中our website construction'\n",
    "masque4 = data_unique3['words'] == cut5\n",
    "move_line = data_unique4.loc[masque4].index\n",
    "data_unique5 = data_unique4.drop(move_line)\n",
    "#data_unique4.loc[masque4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'erstell deinen kostenlos account model live sex webcams verfügbar tritt weltweit groß webcam community'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut6 = 'index modified size cgi bin proudly serve litespeed web server port'\n",
    "masque5 = data_unique5['words'] == cut6\n",
    "move_line = data_unique5.loc[masque5].index\n",
    "data_unique6 = data_unique5.drop(move_line)\n",
    "data_unique6.describe().words.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorie = df[\"category\"].unique()\n",
    "len(categorie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first without threads\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "def get_dataSet(file_name: str):\n",
    "    \"\"\"\n",
    "    Read a JSON file containing domain names, extract the keywords associated with each address and return a pandas Dataframe containing the extracted information\n",
    "\n",
    "    Args:\n",
    "        file_name (str): json file \n",
    "\n",
    "    Returns:\n",
    "        Dataframe: Panda Dataframe with extracted data\n",
    "    \"\"\"\n",
    "       \n",
    "    # creates an instance of the Scraping class   \n",
    "    scrap = Scraping()\n",
    "    clean = TextCleaner()\n",
    "\n",
    "    # open the JSON file and extract the information\n",
    "    with open(file_name, \"r\") as f:\n",
    "        domaines = f.readlines()\n",
    "\n",
    "    # Initialise lists to store data\n",
    "    indices = []\n",
    "    names = []\n",
    "    categories = []\n",
    "    addresses = []\n",
    "    keywords = []\n",
    "\n",
    "    # Iterate through each domain name, extract the keywords associated with the address and store the data in the lists\n",
    "    for index, domaine in tqdm(enumerate(domaines[:50]), total=len(domaines)):\n",
    "        try:\n",
    "            dict_domaine = json.loads(domaine)\n",
    "            name = dict_domaine['name'] \n",
    "            category = dict_domaine['category']\n",
    "            address = dict_domaine['address']\n",
    "            content = dict(scrap.url_content(address))\n",
    "            \n",
    "            if content[\"lang\"] != \"None\":\n",
    "                text = clean.clean_text(content['content_text'], content['lang'])\n",
    "                keywords.append(text)\n",
    "\n",
    "            indices.append(index)\n",
    "            names.append(name)\n",
    "            categories.append(category)\n",
    "            addresses.append(address)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'extraction des données pour le domaine à l'index {index}: {e}\")\n",
    "\n",
    "    # Create a pandas Dataframe containing the extracted data\n",
    "    data = {'name': names, 'category': categories, 'address': addresses, 'words': keywords}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = get_dataSet('urls.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en\n",
      "welcome page nginx web server successfully instal work configuration require online documentation support refer commercial support available thank nginx\n"
     ]
    }
   ],
   "source": [
    "scrap = Scraping()\n",
    "clean = TextCleaner()\n",
    "\n",
    "url = \"https://free-sexpics.us\"\n",
    "\n",
    "content = dict(scrap.url_contents(url))\n",
    "\n",
    "#print(content)\n",
    "print(content[\"lang\"])\n",
    "\n",
    "if content[\"lang\"] != \"None\":\n",
    "    print(content[\"lang\"])\n",
    "\n",
    "    text = clean.clean_text(content['content_text'], content['lang'])\n",
    "    print(text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
